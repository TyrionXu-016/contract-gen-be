"""
å‘é‡æ•°æ®åº“ç®¡ç†å™¨
"""
import config
import numpy as np
import os
import shutil
import datetime
from api.dbManager.BGEModel import BGEModel
from api.Segment.contract_split import *
from typing import List, Union

class VectorDBManager:
    """å‘é‡æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, persist_directory: str = None):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            persist_directory: æ•°æ®åº“å­˜å‚¨ç›®å½•
        """
        import chromadb
        from chromadb.config import Settings
        
        self.persist_directory = persist_directory or config.VECTOR_DB_DIR
        
        # åˆ›å»ºå­˜å‚¨ç›®å½•
        import os
        os.makedirs(self.persist_directory, exist_ok=True)
        
        # åˆå§‹åŒ–ChromaDBå®¢æˆ·ç«¯
        self.client = chromadb.PersistentClient(
            path=self.persist_directory,
            settings=Settings(anonymized_telemetry=False)
        )
        
        # åˆå§‹åŒ–BGEæ¨¡å‹
        self.bge_model = BGEModel()        
        
        # è·å–æˆ–åˆ›å»ºé›†åˆ
        self.contract_collection = self.client.get_or_create_collection(
            name=config.COLLECTION_CONTRACTS,
            metadata={"description": "åˆåŒæ¨¡æ¿é›†åˆ"}
        )
        
        self.law_collection = self.client.get_or_create_collection(
            name=config.COLLECTION_LAWS,
            metadata={"description": "æ³•å¾‹æ³•è§„é›†åˆ"}
        )

        self.case_collection = self.client.get_or_create_collection(
            name=config.COLLECTION_CASE,
            metadata={"description": "æ³•å¾‹æ¡ˆä¾‹é›†åˆ"}
        )
        
    def add_contract_template(self, content: str, metadata: dict) -> dict:
        """
        æ·»åŠ åˆåŒæ¨¡æ¿ï¼ˆåŒ…å«åˆ†æ®µå¤„ç†ï¼‰
        
        Args:
            content: åˆåŒå†…å®¹
            metadata: å…ƒæ•°æ®
            
        Returns:
            åŒ…å«æ¨¡æ¿IDå’Œåˆ†æ®µIDçš„å­—å…¸
        """
        import uuid
        
        # ç”Ÿæˆæ¨¡æ¿ID
        template_id = metadata.get("id") or str(uuid.uuid4())
        
        # 1. åˆ†æ®µå¤„ç†
        segments = split_contract(content, data_type="contract")
        segment_embeddings = []
        for i in range(len(segments)):
            if i%10 == 0:
                print(f"==å‘é‡åŒ–ç¬¬{i}-{i+10}æ®µåˆåŒæ–‡æœ¬==")
            embeddings = self.bge_model.encode(segments[i])
            segment_embeddings.append(embeddings)
        segment_embeddings = np.array(segment_embeddings)
        
        # 2. æ•´ä½“åˆåŒå‘é‡ç”Ÿæˆï¼ˆåŠ æƒå¹³å‡ï¼‰
        # è¿™é‡Œå¯ä»¥æ ¹æ®åˆ†æ®µçš„é‡è¦æ€§è¿›è¡ŒåŠ æƒï¼Œç®€åŒ–ç‰ˆæœ¬ä½¿ç”¨ç®€å•å¹³å‡
        if len(segment_embeddings) > 0:
            # ç®€å•å¹³å‡
            template_embedding = segment_embeddings.mean(axis=0).tolist()
        else:
            # å¦‚æœæ²¡æœ‰åˆ†æ®µï¼Œç›´æ¥ç¼–ç æ•´ä¸ªæ–‡æœ¬
            template_embedding = self.bge_model.encode(content).tolist()
            
        # 3. å­˜å‚¨æ•´ä½“æ¨¡æ¿
        self.contract_collection.add(
            documents=[content],
            embeddings=template_embedding,
            metadatas=[metadata],
            ids=[template_id]
        )
        
        return {
            "template_id": template_id,
            "segment_count": len(segments),
            "embedding_dim": len(template_embedding)
        }
    
    def add_law_regulation(self, content: str, metadata: dict) -> str:
        """
        æ·»åŠ æ³•å¾‹æ³•è§„
        
        Args:
            content: æ³•å¾‹æ¡æ–‡å†…å®¹
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ³•è§„ID
        """
        import uuid
        
        regulation_id = metadata.get("id") or str(uuid.uuid4())
        
        #  åˆ†æ®µå¤„ç†
        segments = split_contract(content, data_type="law")
        for i in range(len(segments)):
            if i%10 == 0:
                print(f"==å‘é‡åŒ–ç¬¬{i}-{i+10}æ®µæ³•å¾‹æ–‡æœ¬==")
            embeddings = self.bge_model.encode(segments[i])

            # å­˜å‚¨ TODO æ³•å¾‹æ³•è§„æ˜¯å¦ä¸éœ€è¦æ•´ä½“å­˜å‚¨ï¼Œåªå­˜åˆ†æ®µï¼Ÿ
            self.law_collection.add(
                documents=[segments[i]],
                embeddings=embeddings,
                metadatas=[metadata],
                ids=[regulation_id]
            )

        return regulation_id
    
    def add_case_template(self, content: str, metadata: dict) -> str:
        """
        æ·»åŠ æ³•å¾‹æ¡ˆä¾‹
        
        Args:
            content: æ³•å¾‹æ¡ˆä¾‹å†…å®¹
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ³•å¾‹æ¡ˆä¾‹ID
        """
        import uuid
        
        regulation_id = metadata.get("id") or str(uuid.uuid4())
        
        #  åˆ†æ®µå¤„ç†
        segments = split_contract(content, data_type="case")
        segment_embeddings = []
        for i in range(len(segments)):
            if i%10 == 0:
                print(f"==å‘é‡åŒ–ç¬¬{i}-{i+10}æ®µæ¡ˆä¾‹æ–‡æœ¬==")
            embeddings = self.bge_model.encode(segments[i])
            segment_embeddings.append(embeddings)
        segment_embeddings = np.array(segment_embeddings)

        # æ•´ä½“æ¡ˆä¾‹å‘é‡ç”Ÿæˆï¼ˆåŠ æƒå¹³å‡ï¼‰
        # è¿™é‡Œå¯ä»¥æ ¹æ®åˆ†æ®µçš„é‡è¦æ€§è¿›è¡ŒåŠ æƒï¼Œç®€åŒ–ç‰ˆæœ¬ä½¿ç”¨ç®€å•å¹³å‡
        if len(segment_embeddings) > 0:
            # ç®€å•å¹³å‡
            template_embedding = segment_embeddings.mean(axis=0).tolist()
        else:
            # å¦‚æœæ²¡æœ‰åˆ†æ®µï¼Œç›´æ¥ç¼–ç æ•´ä¸ªæ–‡æœ¬
            template_embedding = self.bge_model.encode(content).tolist()

        # å­˜å‚¨
        self.case_collection.add(
            documents=[content],
            embeddings=template_embedding,
            metadatas=[metadata],
            ids=[regulation_id]
        )
        
        return regulation_id

    def search_with_filter(self, query: str, filter_conditions: dict = None, 
                          collection_name: str = "contracts", n_results: int = 5) -> dict:
        """
        å¸¦æ¡ä»¶è¿‡æ»¤çš„å‘é‡æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            filter_conditions: è¿‡æ»¤æ¡ä»¶
            collection_name: é›†åˆåç§°ï¼ˆcontracts/laws/case)
            n_results: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœ
        """
        # è·å–æŒ‡å®šé›†åˆ
        if collection_name == "contracts":
            collection = self.contract_collection
        elif collection_name == "laws":
            collection = self.law_collection
        elif collection_name == "case":
            collection = self.case_collection
        else:
            raise ValueError(f"æœªçŸ¥çš„é›†åˆåç§°: {collection_name}")
            
        # å‘é‡åŒ–æŸ¥è¯¢æ–‡æœ¬
        query_embedding = self.bge_model.encode(query).tolist()
        
        # æ„å»ºwhereæ¡ä»¶
        where_conditions = None
        if filter_conditions:
            # è½¬æ¢è¿‡æ»¤æ¡ä»¶ä¸ºChromaDBæ ¼å¼
            where_conditions = {}
            for key, value in filter_conditions.items():
                if isinstance(value, list):
                    where_conditions[key] = {"$in": value}
                else:
                    where_conditions[key] = value
                    
        # æ‰§è¡ŒæŸ¥è¯¢
        results = collection.query(
            query_embeddings=[query_embedding],
            n_results=min(n_results, 100),
            where=where_conditions,
            include=["documents", "metadatas", "distances", "embeddings"]
        )
        
        return results
    
    def dual_matching(self, user_query: str, user_filters: dict = None) -> dict:
        """
        åŒé‡åŒ¹é…ï¼šåŒ¹é…åˆåŒæ¨¡æ¿å’Œæ³•å¾‹æ³•è§„
        
        Args:
            user_query: ç”¨æˆ·æŸ¥è¯¢ï¼ˆè‡ªç„¶è¯­è¨€æè¿°ï¼‰
            user_filters: ç”¨æˆ·ç­›é€‰æ¡ä»¶
            
        Returns:
            åŒ¹é…ç»“æœ
        """
        # 1. åˆåŒæ¨¡æ¿åŒ¹é…
        contract_results = self.search_with_filter(
            query=user_query,
            filter_conditions=user_filters,
            collection_name="contracts",
            n_results=config.MAX_CONTRACT_RESULTS
        )
        
        # 2. æ³•å¾‹æ³•è§„åŒ¹é…
        law_results = self.search_with_filter(
            query=user_query,
            filter_conditions=user_filters,
            collection_name="laws",
            n_results=config.MAX_LAW_RESULTS
        )
        
        # 3. æ³•å¾‹æ¡ˆä¾‹åŒ¹é… åˆ†æ®µåŒ¹é…ï¼ˆç”¨äºç»†ç²’åº¦æ£€ç´¢ï¼‰
        case_results = self.search_with_filter(
            query=user_query,
            filter_conditions=user_filters,
            collection_name="case",
            n_results=config.MAX_CASE_RESULTS
        )
        
        # å¤„ç†ç»“æœ
        processed_contracts = []
        for i in range(len(contract_results['ids'][0])):
            contract = {
                "id": contract_results['ids'][0][i],
                "content": contract_results['documents'][0][i],
                "metadata": contract_results['metadatas'][0][i],
                "similarity": 1 - contract_results['distances'][0][i],
                "embedding": contract_results['embeddings'][0][i] if contract_results['embeddings'] else None
            }
            processed_contracts.append(contract)           
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        processed_contracts.sort(key=lambda x: x["similarity"], reverse=True)
        
        # å¤„ç†æ³•å¾‹æ³•è§„
        processed_laws = []
        for i in range(len(law_results['ids'][0])):
            law = {
                "id": law_results['ids'][0][i],
                "content": law_results['documents'][0][i],
                "metadata": law_results['metadatas'][0][i],
                "similarity": 1 - law_results['distances'][0][i]
            }
            processed_laws.append(law)            
        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„æ³•å¾‹æ³•è§„
        processed_laws = [law for law in processed_laws if law["similarity"] >= config.SIMILARITY_THRESHOLD]
        processed_laws.sort(key=lambda x: x["similarity"], reverse=True)
        
        # å¤„ç†æ¡ˆä¾‹
        processed_case = []
        for i in range(len(case_results['ids'][0])):
            case = {
                "id": case_results['ids'][0][i],
                "content": case_results['documents'][0][i],
                "metadata": case_results['metadatas'][0][i],
                "similarity": 1 - case_results['distances'][0][i],
            }
            processed_case.append(case)
        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„æ³•å¾‹æ¡ˆä¾‹
        processed_case = [case for case in processed_case if case["similarity"] >= config.SIMILARITY_THRESHOLD]
        processed_case.sort(key=lambda x: x["similarity"], reverse=True)
        

        # é€‰æ‹©æœ€åŒ¹é…çš„åˆåŒå’Œå¤‡ç”¨åˆåŒ
        best_contract = processed_contracts[0] if processed_contracts else None
        alternative_contracts = processed_contracts[1:4] if len(processed_contracts) > 1 else []
        
        return {
            "best_contract": best_contract,
            "alternative_contracts": alternative_contracts,
            "relevant_laws": processed_laws,
            "relevant_case": processed_case,
            "query": user_query,
            "filters": user_filters
        }

    def backup_database(self, backup_name: str = None, backup_dir: str = None):
        """
        å¤‡ä»½æ•°æ®åº“åˆ°æŒ‡å®šç›®å½•
        
        Args:
            backup_name: å¤‡ä»½åç§°ï¼Œé»˜è®¤ä¸ºæ—¶é—´æˆ³
            backup_dir: å¤‡ä»½ç›®å½•ï¼Œé»˜è®¤ä¸ºåŸæ•°æ®åº“ç›®å½•çš„åŒçº§backupsç›®å½•
            
        Returns:
            å¤‡ä»½è·¯å¾„
        """
        if backup_name is None:
            backup_name = f"backup_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        # ç¡®å®šå¤‡ä»½ç›®å½•
        if backup_dir is None:
            # é»˜è®¤ä¸ºæ•°æ®åº“ç›®å½•çš„åŒçº§backupsç›®å½•
            base_dir = os.path.dirname(self.persist_directory)
            backup_dir = os.path.join(base_dir, "backups")
        
        # åˆ›å»ºå¤‡ä»½ç›®å½•
        os.makedirs(backup_dir, exist_ok=True)
        
        backup_path = os.path.join(backup_dir, backup_name)
        
        # å¦‚æœå¤‡ä»½ç›®å½•å·²å­˜åœ¨ï¼Œå…ˆåˆ é™¤
        if os.path.exists(backup_path):
            shutil.rmtree(backup_path)
        
        # å¤åˆ¶æ•´ä¸ªå‘é‡æ•°æ®åº“ç›®å½•
        if os.path.exists(self.persist_directory):
            print(f"ğŸ” æ­£åœ¨å¤‡ä»½å‘é‡æ•°æ®åº“ä» {self.persist_directory} åˆ° {backup_path}")
            
            # ä½¿ç”¨copytreeå¤åˆ¶ç›®å½•
            shutil.copytree(self.persist_directory, backup_path)
            
            # è®°å½•å¤‡ä»½ä¿¡æ¯
            info_file = os.path.join(backup_path, "backup_info.json")
            backup_info = {
                "backup_time": datetime.datetime.now().isoformat(),
                "source_path": self.persist_directory,
                "backup_path": backup_path,
                "collection_count": len(self.client.list_collections()),
                "backup_name": backup_name,
                "collection_names": [col.name for col in self.client.list_collections()]
            }
            
            import json
            with open(info_file, 'w', encoding='utf-8') as f:
                json.dump(backup_info, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… æ•°æ®åº“å¤‡ä»½å®Œæˆ: {backup_path}")
            return backup_path
        
        print(f"âš ï¸  æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨: {self.persist_directory}")
        return None
    
    def restore_database(self, backup_name: str, backup_dir: str = None):
        """
        ä»å¤‡ä»½æ¢å¤æ•°æ®åº“
        
        Args:
            backup_name: å¤‡ä»½åç§°
            backup_dir: å¤‡ä»½ç›®å½•ï¼Œé»˜è®¤ä¸ºåŸæ•°æ®åº“ç›®å½•çš„åŒçº§backupsç›®å½•
            
        Returns:
            bool: æ¢å¤æ˜¯å¦æˆåŠŸ
        """
        # ç¡®å®šå¤‡ä»½ç›®å½•
        if backup_dir is None:
            # é»˜è®¤ä¸ºæ•°æ®åº“ç›®å½•çš„åŒçº§backupsç›®å½•
            base_dir = os.path.dirname(self.persist_directory)
            backup_dir = os.path.join(base_dir, "backups")
        
        backup_path = os.path.join(backup_dir, backup_name)
        
        if not os.path.exists(backup_path):
            # å°è¯•ç›´æ¥ä½¿ç”¨backup_nameä½œä¸ºå®Œæ•´è·¯å¾„
            if os.path.exists(backup_name):
                backup_path = backup_name
            else:
                raise FileNotFoundError(f"å¤‡ä»½ä¸å­˜åœ¨: {backup_path}")
        
        # æ£€æŸ¥å¤‡ä»½ä¿¡æ¯æ–‡ä»¶
        info_file = os.path.join(backup_path, "backup_info.json")
        if os.path.exists(info_file):
            import json
            with open(info_file, 'r', encoding='utf-8') as f:
                backup_info = json.load(f)
            print(f"ğŸ“‹ æ­£åœ¨æ¢å¤å¤‡ä»½: {backup_info.get('backup_name', backup_name)}")
            print(f"ğŸ“… å¤‡ä»½æ—¶é—´: {backup_info.get('backup_time')}")
        
        print(f"ğŸ” æ­£åœ¨ä»å¤‡ä»½æ¢å¤: {backup_path} -> {self.persist_directory}")
        
        # å…³é—­å½“å‰å®¢æˆ·ç«¯è¿æ¥
        try:
            del self.client
        except:
            pass
        
        # å¦‚æœç›®æ ‡ç›®å½•å­˜åœ¨ï¼Œå…ˆæ¸…ç©º
        if os.path.exists(self.persist_directory):
            print(f"ğŸ§¹ æ¸…ç©ºç°æœ‰æ•°æ®åº“ç›®å½•: {self.persist_directory}")
            shutil.rmtree(self.persist_directory)
        
        # ä»å¤‡ä»½æ¢å¤
        shutil.copytree(backup_path, self.persist_directory)
        
        # é‡æ–°åˆå§‹åŒ–å®¢æˆ·ç«¯å’Œé›†åˆ
        try:
            import chromadb
            from chromadb.config import Settings
            
            self.client = chromadb.PersistentClient(
                path=self.persist_directory,
                settings=Settings(anonymized_telemetry=False)
            )
            
            # é‡æ–°è·å–é›†åˆ
            self.contract_collection = self.client.get_collection(name=config.COLLECTION_CONTRACTS)
            self.law_collection = self.client.get_collection(name=config.COLLECTION_LAWS)
            self.case_collection = self.client.get_collection(name=config.COLLECTION_CASE)
            
            print(f"âœ… æ•°æ®åº“å·²æˆåŠŸä»å¤‡ä»½æ¢å¤: {backup_name}")
            print(f"ğŸ“Š æ¢å¤çš„é›†åˆæ•°é‡: {len(self.client.list_collections())}")
            return True
            
        except Exception as e:
            print(f"âŒ æ¢å¤æ•°æ®åº“æ—¶å‡ºé”™: {str(e)}")
            raise